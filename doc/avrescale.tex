%\documentclass[12pt]{article}
\documentclass[reprint]{revtex4-1}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{upgreek}
\usepackage[table,usenames,dvipsnames]{xcolor}
\usepackage{hyperref}

\hypersetup{
  colorlinks,
  linkcolor={red!30!black},
  citecolor={green!20!black},
  urlcolor={blue!80!black}
}


\definecolor{DarkBlue}{RGB}{0,0,64}
\definecolor{DarkBrown}{RGB}{64,20,10}
\definecolor{DarkGreen}{RGB}{0,64,0}
\definecolor{DarkPurple}{RGB}{64,0,42}
\definecolor{LightGray}{gray}{0.85}
% annotation macros
\newcommand{\red}[1]{{\color{red} #1}}
\newcommand{\repl}[2]{{\color{gray} [#1] }{\color{blue} #2}}
\newcommand{\add}[1]{{\color{blue} #1}}
\newcommand{\del}[1]{{\color{gray} [#1]}}
\newcommand{\note}[1]{{\color{DarkGreen}\footnotesize \textsc{Note.} #1}}
\newcommand{\answer}[1]{{\color{DarkBlue}\footnotesize \textsc{Answer.} #1}}
\newcommand{\summary}[1]{{\color{DarkPurple}\footnotesize \textsc{Summary.} #1}}



\begin{document}



\title{Adaptive velocity scaling for an asymptotic
microcanonical ensemble}
\author{}
%\date{\vspace{-7ex}}
\begin{abstract}
  We present a modification of the commonly-used
  temperature control scheme: velocity scaling.
  %
  The usual velocity scaling scheme is incompatible with
  the microcanonical ($NVE$) ensemble
  as the scaling operation causes the total energy to fluctuate continually.
  %
  Our modification gradually reduces the scaling magnitude
  by the number of steps
  and thereby achieves an asymptotic microcanonical ensemble,
  where the microcanonical temperature tends to the target value
  at an optimal rate.
\end{abstract}

\maketitle



Velocity scaling is a temperature control scheme
for molecular dynamics (MD) simulations.
%
In a common version,
the velocity is regularly scaled such that the average
kinetic energy of the past few steps, $\bar K$,
can match the expected value,
$K^* = \frac{1}{2} N_f \, k_B \, T$\cite{frenkel},
where $N_f$, $k_B$, and $T$ are the number of degrees of freedom,
the Boltzmann constant, and temperature, respectively.
%
We refer to this version as the regular velocity scaling below.
%
A somewhat gentler modification, the Berendsen thermostat\cite{berendsen1984},
modifies the scaling scheme, such that
the kinetic energy approaches the target value at a rate of
$\left( K^* - \bar K \right)/\tau$,
with $\tau^{-1}$ being the rate of damping.

The above schemes, albeit effective,
do not result in exact sampling for the microcanonical ($NVE$) ensemble\cite{hermansson1988},
because they cause the total energy to fluctuate continually.
%
Thus, they are often regarded as expedient protocols
suitable only for parameter tuning in preliminary runs,
but not for rigorous MD simulations in the microcanonical ensemble.
%
However, in several ingenious modifications,
the energy fluctuation of velocity scaling
can be used to design thermostat algorithms
for the canonical ($NVT$) ensemble, in which the total energy
is intrinsically fluctuating.
%
These modifications,
exemplified by the Nos\'e-Hoover\cite{nose1984, nose1984mp, hoover1985, martyna1992}
and Langevin-style velocity rescaling\cite{bussi2007} thermostats,
are exact algorithms, as
the velocity scaling operation is carefully
controlled to make
the resulting fluctuation of the total energy
mimic the natural behavior demanded by the underlying canonical ensemble.
%
Albeit the success and popularity of the thermostat algorithms,
one may argue that these algorithms often introduce
some artificial time scales that are foreign to the natural time evolution.

Here we present a modified velocity scaling scheme
for an asymptotic microcanonical ensemble,
in which
the total energy is gradually stabilized to a value
that corresponds to the target temperature.
%
Our modification is inspired by the $1/t$ scheme\cite{
  belardinelli2007, belardinelli2007jcp, belardinelli2008,
  zhou2005, zhou2008, morozov2007}
for improving the convergence of the Wang-Landau algorithm\cite{
  wang2001, wang2001pre}.
The WL algorithm,
which falls in a larger class of free energy methods
of metadynamics\cite{
  laio2002, laio2008, marsili2006},
has parameters for the entropy that need to be
determined and updated adaptively,
and the $1/t$ scheme gives the optimal updating magnitude
for the parameters to reach their ideal values.
%
In analogy, we may compare the total energy here
to a parameter in the WL algorithm,
and argue that the optimal magnitude
of velocity scaling should be inversely proportional
to the number of steps.
%
Besides the above change,
our modification will target a more accurate
microcanonical temperature\cite{rugh1997},
which differs from the usual definition of
twice the kinetic energy per degree of freedom
derived from the canonical ensemble.



\section{Methods}



\subsection{Background in Statistical Mechanics}



Our adaptive velocity scaling scheme aims at
controlling the temperature for an
MD simulation in the microcanonical ensemble.
%
Since the microcanonical ensemble is parameterized by
the total energy, $E$,
our scheme must adjust the total energy
to influence the temperature of the ensemble.


An MD trajectory generated from
Newton's equation of motion
can be thought as a realization
of a microcanonical ensemble,
or a collection of configurations,
with the same total energy.
%
Below we shall denote a configuration in the trajectory
by a vector $\mathbf x$,
specifying the coordinates and momenta.
%
Under the ergodicity hypothesis,
Newton's equation will populate configurations
that spread evenly over
the isoenergetic hypersurface in the phase space,
defined by
$H(\mathbf x) = E$,
where $H(\mathbf x)$ is the Hamiltonian function.
%
The area of the hypersurface gives the density of states,
%
\begin{equation}
  \Omega(E)
  =
  \int
    \delta\bigl( H(\mathbf x) - E \bigr)
    \, d\mathbf x
  ,
  \notag
  %\label{eq:omegaE}
\end{equation}
%
and the microcanonical temperature,
defined via the inverse temperature,
$\beta = 1/(k_B T)$,
is given by
%
\begin{equation}
  \beta(E)
  =
  \frac{ d }{ dE }
  \ln \Omega(E)
  =
  \frac{ \Omega'(E) }
       { \Omega(E)  }
  ,
  \label{eq:betaE_def}
\end{equation}
%
and is, therefore, a function of $E$.
%

By velocity scaling, we want to
find a value of the total energy, $E^*$,
such that the microcanonical temperature
is equal to the target value, $\beta^*$,
i.e., the solution of
%
\begin{equation}
  \beta(E^*)
  =
  \beta^*
  .
  \label{eq:beta_star}
\end{equation}
%
Unfortunately, the function $\beta(E)$
is usually unknown in advance
and must be learned gradually from simulation.
%
So is the solution of Eq. \eqref{eq:beta_star}.
%
Below, we review an adaptive averaging technique
which offers a way
to gradually improve our knowledge of temperature function,
and hence the precision of the desired target energy, $E^*$.



\subsection{Adaptive averaging}



Suppose that in each MD step, $t$,
we may form an independent estimate of $E^*$,
$\mathcal E_t$,
then a more reliable estimate of $E^*$
can be obtained from averaging
all previous independent estimates,
%
\begin{equation}
  \bar{\mathcal E}_t
  =
  \sum_{\tau = 1}^t
    \mathcal E_\tau
  .
  \label{eq:Epsave}
\end{equation}
%
This is a runtime average,
and its precision improves over the simulation course.



Our modified velocity scaling is based on adaptive averaging,
and it differs from the usual version
in that the former uses $\bar{\mathcal E}_t$
instead of $\mathcal E_t$
to guide the amount of energy change in each step.
%
That is, we want
the total energy of the system
at the end of each step
to be given by
the runtime average, $\bar{\mathcal E}_t$.
%instead of $\mathcal E_t$.
%
This condition requires the amount of energy increment
by velocity scaling in step $t$ to be
%
\begin{equation}
  \delta E_t
  =
  \bar{\mathcal E}_t - \bar{\mathcal E}_{t - 1}
  .
  \label{eq:dE_adaptive}
\end{equation}

As the runtime average from Eq. \eqref{eq:Epsave}
stabilizes, the magnitude of velocity scaling
naturally decreases.
%
This can be seen by rewriting Eq. \eqref{eq:Epsave}
as a recurrence relation
%
\begin{align}
  \bar{\mathcal E}_t
  &=
  \frac{1}{t}
  \left[
    (t - 1) \, \bar{\mathcal E}_{t - 1}
    + \mathcal E_t
  \right]
  \notag \\
  &=
  \bar{\mathcal E}_{t - 1}
  +
  \frac{
    \mathcal E_t - \bar{\mathcal E}_{t - 1}
  }
  {
    t
  }
  .
\label{eq:Epsave_recur}
\end{align}
%
Here we may understand $\mathcal E_t - \bar{\mathcal E}_{t - 1}$
as the independent correction
to the current average $\bar{\mathcal E}_{t - 1}$
from the configuration at step $t$,
and Eq. \eqref{eq:Epsave_recur} shows that
when the correction is absorbed in the runtime average
it carries the weight of $1/t$.
%
From Eqs. \eqref{eq:dE_adaptive} and \eqref{eq:Epsave_recur},
we obtain the optimal amount of energy change
for each MD step
\begin{align}
  \delta E_t
  =
  \frac{ 1 } { t }
  \cdot
  \left( \mathcal E_t - \bar{\mathcal E}_{t - 1} \right)
  .
  \label{eq:dE_opt}
\end{align}
%
This amount of energy change is to be realized by velocity scaling
%
Equation \eqref{eq:dE_opt} is analogous to the $1/t$, prescription\cite{
  belardinelli2007, belardinelli2007jcp, belardinelli2008,
  zhou2005, zhou2008, morozov2007}
for the optimal control of the updating magnitude
of the Wang-Landau algorithm\cite{wang2001, wang2001pre},
and the above derivation results from its close connection\cite{
  marsili2006, barducci2008}
to the adaptive biasing force method\cite{darve2001, darve2008}.
%
In Appendix \ref{sec:error}, we give an alternative derivation of the result.



\subsection{Linearization}



Next, we need to form an independent estimate of
$\mathcal E_t$ of $E^*$.
%
For this, we shall form
an independent estimate of temperature, $\beta_t$
(detailed in the next subsection)
and solve a linearized version of Eq. \eqref{eq:beta_star}.

Linearizing Eq. \eqref{eq:beta_star} around the solution
yields
%
\begin{equation*}
\beta^*
\approx
\beta( E )
+
\beta'( E^* ) \, ( E^* - E )
,
%\label{eq:beta_linear}
\end{equation*}
%
or
%
\begin{equation}
E^*
\approx
E
+
\frac{ \beta^* - \beta(E) }
     { \beta'(E^*) }
.
\label{eq:E_inversion}
\end{equation}
%
In our adaptive velocity scaling scheme,
we require the total energy at the beginning of every step
(before scaling) to match the average value $\bar{\mathcal E}_{t - 1}$.
%
Thus, if we use $\bar{\mathcal E}_{t - 1}$ for $E$
and $\beta_t$ for $\beta(E)$
in Eq. \eqref{eq:E_inversion},
$E^*$ would be the independent estimate
$\mathcal E_{t}$ at step $t$:
%
%
\begin{equation}
\mathcal E_t
=
\bar{\mathcal E}_{t - 1}
+
\frac{ \beta^* - \beta_t }
     { \beta'(E^*) }
.
\label{eq:Eps}
\end{equation}
%
Thus, the optimal energy increment,
from Eqs. \eqref{eq:dE_opt} and \eqref{eq:Eps},
is
%
\begin{equation}
\delta E_t
=
\frac{ 1 } { t }
\cdot
\frac{ \beta^* - \beta_t }
     { \beta'(E^*) }
.
\label{eq:dE_beta}
\end{equation}
%



\subsection{Microcanonical temperature}


We now specify formulas for $\beta_t$
and $\beta'(E)$ required in Eq. \eqref{eq:dE_beta}.
%
It can be shown that both the microcanonical temperature, $\beta(E)$,
and $\beta'(E)$ can be evaluated as
averages in the microcanonical ensemble\cite{rugh1997, frenkel}:
%
\begin{equation}
  \beta(E)
  =
  \left\langle
    \frac{ N_f - 2 }
         { 2 \, K }
  \right\rangle_E
  ,
  \label{eq:betaE_invK}
\end{equation}
%
and
%
\begin{equation}
  \beta'(E)
  =
  - \left\langle
      \frac{ N_f - 2 }
           { 2 \, K^2 }
    \right\rangle_E
  + \left\langle
      \Delta\left(
        \frac{ N_f - 2 }
             { 2 \, K }
      \right)^2
    \right\rangle_E
  ,
  \label{eq:dbetadE}
\end{equation}
%
where
$\langle \Delta A^2 \rangle = \langle A^2 \rangle - \langle A \rangle^2$
means the variance of quantity $A$.
%
%We will use Eq. \eqref{eq:dbetadE} to gauge
%the magnitude of adjusting the velocity-scaling factor.
Note that the usual definition of temperature from twice the kinetic energy
per degree of freedom is, however,
derived from the canonical ensemble and
inexact for the microcanonical ensemble.



Now if we use Eq. \eqref{eq:betaE_invK} and
the one-step estimate for the inverse temperature
$\beta_t$,
then the optimal energy increment is given by
Eq. \eqref{eq:dE_beta}:
%
\begin{equation}
\delta E_t
=
\frac{ 1 } { t } \cdot
\frac{ 1 } { \beta'(E^*) }
\left(
 \beta^* -
 \frac{ N_f - 2  }
      { 2 \, K_t }
\right)
,
\label{eq:dE_final}
\end{equation}
%
where
$K_t$ is the kinetic energy before velocity scaling at step $t$,
and $\beta'(E^*)$ can be approximated
as
%
\begin{align}
  \beta'(E^*)
  \approx
  - \overline{
    \left(
      \frac{ N_f - 2 }
           { 2 \, K_t^2 }
    \right)
    }
    +
    \operatorname{Var}
    \left(
        \frac{ N_f - 2 }
             { 2 \, K_t }
    \right)
  ,
  \label{eq:dbeta}
\end{align}
%
where
$\overline A$ means the trajectory average of $A$,
and
$\operatorname{Var}(A) = \overline{ A^2 } - {\overline A}^2$
is the corresponding variance.
%


\subsection{Approximations on $\beta'(E^*)$}


Ideally, we should have $\beta'(E) \le 0$
as the temperature $T$ increases the total energy $E$.
%
This, however, may not be true in practice
because of the numerical error of the second variance term on the right-hand side
of Eq. \eqref{eq:dbeta}.
%
%Further, since the variance is nonnegative, we have
%%
%\begin{equation*}
%  - \overline{
%    \left(
%      \frac{ N_f - 2 }
%           { 2 \, K_t^2 }
%    \right)
%    }
%  \le
%  \beta'(E^*)
%  \le
%  0,
%\end{equation*}
%
A useful approximation that avoids the variance is the following
%
\begin{equation}
  \beta'(E^*)
  =
  -\gamma \, \overline{
    \left(
      \frac{ N_f - 2 }
           { 2 \, K_t^2 }
    \right)
    }
  ,
  \label{eq:dbeta_approx}
\end{equation}
%
where we have defined the ratio $\gamma$ as
%
\begin{equation}
  \gamma
  \equiv
  \frac
  {
    -\beta'(E^*)
  }
  {
    \overline{
      \left( \frac 1 2 N_f - 1  \right) / K_t^2
    }
  }
  .
  \label{eq:gamma_def}
\end{equation}
%
For for a physical system, we expect $0 \le \gamma \le 1$.


We may use Eq. \eqref{eq:dbeta_approx} in two ways.
%
First, as a safety measure in an early stage of simulation,
we may propose a minimal value of $\gamma$, say $0.1$,
and when the value from Eq. \eqref{eq:dbeta}
exceeds that from Eq. \eqref{eq:dbeta_approx},
we will use the latter instead of the former.

Second, from
Eqs. \eqref{eq:dbeta_approx} and \eqref{eq:dbeta_approx2},
we have
%
\begin{equation}
  \beta'(E^*)
  =
  -\frac{ \gamma \, {\beta^*}^2 }
  { \frac{1}{2} N_f + \gamma - 2 }
  .
  \label{eq:dbeta_approx2}
\end{equation}
%
We can determine some heuristic value of $\gamma$
for certain type of systems,
then use Eq. \eqref{eq:dbeta_approx2}
instead of Eq. \eqref{eq:dbeta}.
%
For example,
for an explicit solvent simulation of TIP3P water\cite{jorgensen1983}
at 300K, we find that the optimal $\gamma$
to be around $0.33$.



\subsection{Scaling frequency}


In practice, velocity scaling is often implemented every few,
say $m$ ($m > 1$), MD steps.
%
Then,
%$t$ should be understood as the number of
%such velocity-scaling operations so far instead of
%the number of MD steps, and
$K_t$ in Eq. \eqref{eq:dE_final} is understood
as the average kinetic energy $\bar K$ of the $m$ steps
before the scaling operation.



\section{Results}



We coded the adaptive velocity scaling scheme to
the MD program NAMD\cite{NAMD},
and tested it on a system
of $798$ TIP3P water molecules\cite{jorgensen1983}
in a cubic box of $30 \, \mathrm{\AA}$ side length.
%
Velocity scaling was conducted every $10$ steps
unless specified otherwise.
%
The MD time step was $2$ femtoseconds;
the temperature was $300$ K.
%
We used the particle-meshed Ewald method\cite{essmann1995}
with a spacing of $1 \, \mathrm{\AA}$
to compute the electrostatic interaction,
and the SETTLE method\cite{miyamoto1992}
to maintain the constraints.


We first compared the time series of the total energy
from simulations
under regular and adaptive velocity scaling
and that from a regular MD simulation without velocity scaling.
%
In the case of regular velocity scaling,
as described in the Introduction,
velocity was scaled every $10^3$ MD steps.
%
For adaptive velocity scaling,
$\beta'(E^*)$ was computed from Eq. \eqref{eq:dbeta},
and we obtained from this simulation
the heuristic value of $\gamma = 0.33$,
to be used for other tests.
%
The regular MD conserves the total energy
within the error of the integration scheme,
and we have adjusted the initial total energy of this simulation
to the converged value from the adaptive velocity scaling simulation.
%
As shown in Fig. \ref{fig:etraj},
despite a low scaling frequency,
regular velocity scaling
produced considerable fluctuation in the total energy
whose magnitude roughly maintains a constant.
%
In contrast, adaptive velocity scaling
was able to quickly reduce the fluctuation of the total energy
to a level comparable to that
from a regular MD without velocity scaling.

\begin{figure}[h]
\begin{center}
  \makebox[\linewidth][c]{
    \includegraphics[angle=0, width=1.0\linewidth]{fig/etraj.pdf}
  }
  \caption{
    \label{fig:etraj}
    The time series of the total energy
    from an MD trajectory
    without velocity scaling (with the total energy $E \approx -6141.5$),
    one under regular velocity scaling
    (conducted every $10^3$ steps),
    %(in which the velocity is scaled
    %every $m = 10^4$ steps by a factor of
    %$\sqrt{\frac12 N_f k_B T/\bar K}$,
    %with $\bar K$ being the average kinetic energy
    %of the past $m$ steps),
    and
    one under adaptive velocity scaling (conducted every $10$ steps).
    %
    Each simulation had $10^7$ steps,
    but only the data from the first $3\times 10^6$ steps were shown.
    %
    The points were plotted every $5 \times 10^4$ steps.
    %
    The standard deviations of the total energy,
    excluding the first $10^6$ steps,
    were \red{$0.261$, $7.7$, and $0.263$} $\mathrm{kcal/mol}$,
    respectively.
    %
    \note{The figure was produced by \texttt{doc/fig/etraj.gp}.
      The raw data were saved in
      \texttt{data/wb/fix/ene0fix.log},
      \texttt{data/wb/reg/ene0reg.log},
      and
      \texttt{data/wb/adp/ene0adp.log}.
      The standard deviations can be found with
      \texttt{make etraj -C data/wb}.
    }%
  }
\end{center}
\end{figure}



We then compared the kinetic energy
distribution from a simulation under adaptive velocity scaling
%distributions from the simulations under regular and adaptive velocity scaling,
%that from a regular MD,
and that from an MD targeting a canonical ensemble
at the same temperature (using Langevin dynamics).
%
As shown in Fig. \ref{fig:uhist},
adaptive velocity scaling and regular MD
produced similar distributions,
which were considerably narrower than the distribution
from the canonical counterpart.
%
This is understandable,
as the canonical ensemble
can be constructed as a superposition
of microcanonical ensembles of different $E$'s,
and the distribution from the former ensemble
tends to be broader.
%
%The distribution from regular velocity scaling,
%however, was visibly different from
%that from the microcanonical or canonical ensemble.
%
%More interestingly,
%Fig. 2 shows that the adaptive velocity scaling
%yields shorter correlation for the kinetic energy.

\begin{figure}[h]
\begin{center}
  \makebox[\linewidth][c]{
    \includegraphics[angle=0, width=1.0\linewidth]{fig/uhist.pdf}
  }
  \caption{
    \label{fig:uhist}
    Kinetic energy distributions
    from MD simulations in the canonical ensemble,
    microcanonical ensemble,
    and one under adaptive velocity scaling.
    %
    %Each simulation had $10^7$ steps,
    %and the data from the first $10^6$ steps
    %were dropped.
    %
    \note{The figure was produced by \texttt{doc/fig/uhist.gp}.
      For data preparation, \texttt{make uhist -C data/wb}.
    }%
  }
\end{center}
\end{figure}


We compared the efficiency of the adaptive velocity scaling scheme,
which is designed for the microcanonical ensemble,
to several temperature control schemes for the canonical ensemble.
%
For this purpose, we lifted the total energy about
$100\,\mathrm{kcal/mol}$ above the average,
and monitored the evolution of the kinetic energy.
%
As shown in Fig. \ref{fig:equil},
adaptive velocity scaling
behaved similarly to
the Nos\'e-Hoover chain\cite{nose1984, nose1984mp, hoover1985, martyna1992},
and velocity rescaling\cite{bussi2007}
thermostats
in equilibrating the kinetic energy;
and these velocity-scaling-based schemes
appeared to be more efficient than Langevin dynamics.

\begin{figure}[h]
\begin{center}
  \makebox[\linewidth][c]{
    \includegraphics[angle=0, width=1.0\linewidth]{fig/equil.pdf}
  }
  \caption{
    \label{fig:equil}
    Time series of the total energy
    of simulations under
    adaptive velocity scaling,
    Langevin dynamics,
    Nos\'e-Hoover chain thermostat
    and
    velocity rescaling thermostat.
    %
    For Langevin dynamics,
    the damping parameter was $1.0 \, \mathrm{ps}^{-1}$.
    %
    For the Nos\'e-Hoover chain thermostat,
    we used 5 chain variables. The masses
    of the first and the rest variables
    were $N_f \, \omega^2 \, k_B T$ and
    $\omega^2 \, k_B T$, respectively\cite{martyna1992},
    and
    $\omega = 2 \,\pi/(0.1 \, \mathrm{ps})$.
    %
    For the velocity rescaling thermostat,
    the inverse viscosity $\tau$ was $0.03 \, \mathrm{ps}$.
    %
    The average kinetic energy of the system
    is roughly $1426.3 \, \mathrm{kcal/mol}$.
    %
    \red{The lines are a guide to the eyes.}
    %
    \red{The results were averaged over $10^4$ independent trials.}
    %
    \note{The figure was produced by \texttt{doc/fig/equil.gp}.
    }%
  }
\end{center}
\end{figure}





To test the optimality of Eq. \eqref{eq:dE_final},
we studied a generalized velocity scaling scheme,
in which the energy change in each step is given by
%
\begin{equation}
  \delta E_t
  =
  \frac{ \alpha(t) } { \beta'(E^*) }
  \left(
   \beta^* -
   \frac{ N_f - 2 }
   { 2 \, K_t }
  \right)
  ,
  \label{eq:dE_mod}
\end{equation}
%
where $\alpha(t) = z/t$ with $z$ being a free parameter;
and Eq. \eqref{eq:dE_final} is the $z = 1$ case.
%
For each value of $z$,
we performed multiple independent simulations of $T = 10^5$ steps,
and used the variance of the total energy at the simulation end
to represent the error.
%
For $\beta'(E^*)$,
Eq. \eqref{eq:dbeta_approx2} was used with the heuristic value of $0.33$.
%
As shown in Fig. \ref{fig:errz},
the value of $z = 1$
indeed gives the lowest error.
%
The deviation from the analytical prediction,
Eq. \eqref{eq:err_zovert},
is likely due to the relatively short simulation time,
which does not completely justify the assumption
on the fluctuation of the total energy, Eq. \eqref{eq:noise_corr}.

\begin{figure}[h]
\begin{center}
  \makebox[\linewidth][c]{
    \includegraphics[angle=0, width=1.0\linewidth]{fig/errz.pdf}
  }
  \caption{
    \label{fig:errz}
    Error of the total energy,
    $\left\langle \Delta E^2(T) \right\rangle$,
    at the end of a simulation of $T = 10^5$ steps,
    versus parameter $z$
    for the modified velocity scaling scheme,
    Eq. \eqref{eq:dE_mod}.
    %
    The points are results from averaging over \red{$72$} independent runs;
    the curve is the analytical prediction from
    Eq. \eqref{eq:err_zovert}.
    The value of $\Gamma$ used in the latter was deduced
    using Eq. \eqref{eq:Gamma_alpha0} from
    a long simulation under regular velocity scaling
    with $\alpha_0 = 0.001$.
    %
    \note{The figure was produced by \texttt{doc/fig/errz.gp}.
      The raw data were saved in \texttt{data/wb\_t100000.dat}
    }%
  }
\end{center}
\end{figure}




\section{\label{sec:conclusion}
Conclusions and Discussions}



\section{Acknowledgment}

We thank Dr. J. Ma, Dr. Y. Mei, J. Wang,
J. Drake, O. Nassar, Dr. C. Lai, Dr. S. Ou and D. Stuhlsatz
for helpful discussions.
We gratefully acknowledge the Robert A. Welch Foundation (H-0037),
the National Science Foundation (CHE-1152876)
and
the National Institutes of Health (GM-037657) for partial support of this work.
%
%This research used computing resources of the National Science Foundation XSEDE grid.


\appendix


\section{\label{sec:error}
  Alternative derivation of
  the optimal scaling magnitude
  %Eq. \eqref{eq:dE_opt}
}


Here, we present an alternative derivation of Eq. \eqref{eq:dE_opt},
which shows that if in each step, we can form an independent correction
to the total energy, such a correction should be optimally used
in velocity scaling with an ever-decreasing weight of $1/t$.

Let $E_t$ be the total energy at step $t$,
then the aim of velocity scaling is to converge $E_t$
to the desired value of $E^*$.
%
We assume that we can form an independent estimate of $E^*$
in step $t$, $\mathcal E_t$,
which means, equivalently, an independent correction
to the current total energy, $\mathcal E_t - E_{t-1}$.
%
The correction can be used to guide the amount of
energy change, $\Delta E_t = E_t - E_{t-1}$,
for velocity scaling.
%
If the independent correction were exact,
then velocity scaling only needs to be done once,
with the change $\Delta E_t$ to be identical to the correction.
%
But since the independent correction contains random error,
velocity scaling must be done continually,
and as we shall see,
if we accept the correction with some
optimal time-dependent magnitude, $\alpha(t)$, as
%
\begin{equation}
  \Delta E_t = \alpha(t) \, \left( \mathcal E_t - E_{t - 1} \right)
  ,
  \label{eq:Eupdate}
\end{equation}
%
the expected error of the total energy, $E_T$,
at the end of the simulation, $t = T$, can be minimized.

To find the optimal $\alpha(t)$,
it is more convenient to use the continuous-time framework.
%
We introduce the error of the total energy at step $t$ as
$x(t) = E_{t-1} - E^*$,
then $\dot x(t) \approx \Delta E_t$,
and Eq. \eqref{eq:Eupdate} can be approximated as
%
\begin{equation}
  \dot x(t)
  =
  -\alpha(t) \, x(t) + \alpha(t) \, \xi(t)
  ,
  \label{eq:x_diffeq}
\end{equation}
%
where $\xi(t) \equiv \mathcal E_t - E^*$
denotes the random fluctuation of the independent estimate at step $t$.
%
For simplicity, we will further approximate $\xi(t)$ as a white noise,
such that
\begin{equation}
  \langle \xi(t) \, \xi(t') \rangle = \Gamma \, \delta(t - t').
  \label{eq:noise_corr}
\end{equation}
%
Note that we may only justify this approximation
for a simulation much longer than the autocorrelation time of $\xi(t)$.
%
The solution of Eq. \eqref{eq:x_diffeq} is
%
\begin{equation}
  x(t)
  =
  x(1) \, e^{ -\int_1^t \alpha(\tau) \, d\tau }
  +
  \int_1^t \dot u_t(\tau) \, \xi(\tau) \, d\tau
  ,
  %\label{eq:x_sol}
  \notag
\end{equation}
%
where
\begin{equation}
  u_t(\tau) = \exp\left(
    -\int_\tau^t \alpha(s) \, ds
  \right)
  .
  \notag
\end{equation}
%
Thus, the error at the end of simulation $t = T$,
can be measured as expectation of $x^2(T)$,
%
\begin{equation}
  \left\langle
    x^2(T)
  \right\rangle
  =
  \left\langle
    x^2(1)
  \right\rangle
  \, e^{ -2 \, A(t) }
  +
  \Gamma
  \int_1^T
    \dot u_T^2(t) \, dt
  ,
  \label{eq:err_functional}
\end{equation}
where
$A(t) = \int_1^t \alpha(t) \, dt$.
%
%the total energy change induced by velocity scaling
%is
%
This expression is a functional of $\alpha(t)$,
or equivalently, a functional of $u_T(t)$.
%
To minimize it under a fixed value of $A(T)$,
which implies fixed values of $u_T(1)$ and $u_T(T)$,
we get the condition
$$
\dot u_T(t) = \mathrm{const},
$$
which leads to the solution,
$u_T(t) = (t + t_0) / (T + t_0)$,
with $c$ and $t_0$ being two constants.
%
As a result, we get the optimal scaling magnitude
%
\begin{equation}
  \alpha(t) = \frac{ 1 } { t + t_0 }
  ,
  \notag
  %\label{eq:alpha_opt}
\end{equation}
%
and the error is
%
$$%\begin{equation}
  \left\langle
    x^2(T)
  \right\rangle
  =
  \frac{
    \left\langle x^2(1) \right\rangle
    \, (1 + t_0)^2
    + \Gamma \, (T - 1)
  }
  {
    (T + t_0)^2
  }
  ,
$$%\end{equation}
%
We can further determine the optimal value of $t_0$ as
$$
t_0 = \frac{ \Gamma } { \left\langle x^2(1) \right\rangle } - 1.
$$
%
However, for a long simulation, the influence of $t_0$
is small, and we may approximately use
$$
\alpha(t) \approx \frac 1 t,
$$
This result recovers Eq. \eqref{eq:dE_opt}.

We can further show that Eq. \eqref{eq:dE_mod}
corresponds to a modified schedule
$\alpha(t) = z/t$,
which results in an expected error of
\begin{equation}
  \left\langle
  x^2(T)
  \right\rangle
  =
  \frac{ \langle x^2(1) \rangle } { T^{2z} }
  +
  \frac{ \Gamma \, z^2 } { 2 \, z - 1 }
  \frac{
    T^{2 \, z - 1} - 1
  }
  {
    T^{2 \, z}
  }
  ,
  \label{eq:err_zovert}
\end{equation}
which is minimal at $z = 1$ for a long simulation.

To determine the value of $\Gamma$ of an unknown system,
we may conduct a simulation with the regular velocity scaling,
which corresponds to a constant scaling magnitude
$\alpha(t) = \alpha_0$.
%
From Eq. \eqref{eq:err_functional}, we find that
the error
$\left\langle
  x^2(T)
\right\rangle
=
\Gamma \, \alpha_0 / 2$
is independent of time $T$.
Thus, we can compute $\Gamma$ from the trajectory average
after equilibration,
\begin{equation}
\Gamma
=
\frac{ 2 } { \alpha_0 } \,
\overline{
  \bigl(
    E - \overline E
  \bigr)^2
}
.
\label{eq:Gamma_alpha0}
\end{equation}


\section{Microcanonical temperature and its derivative}


Here we derive Eqs. \eqref{eq:betaE_invK} and \eqref{eq:dbetadE}.
We start by defining a vector field, $\mathbf u$,
such that
%
\begin{equation}
  \mathbf u \cdot \nabla H = 1
  ,
  \label{eq:unormalization}
\end{equation}
%
anywhere, then
%
\begin{align}
  \Omega'(E)
  &= -\int \delta'\bigl( H(\mathbf x) - E \bigr) \, d\mathbf x
     \notag \\
  &= -\int (\mathbf u \cdot \nabla H) \,
           \delta'\bigl( H(\mathbf x) - E \bigr) \, d\mathbf x
     \notag \\
  &= -\int \mathbf u \cdot
           \nabla \delta\bigl( H(\mathbf x) - E \bigr) \, d\mathbf x
     \notag \\
  &= \int \nabla \cdot \mathbf u \,
     \delta\bigl( H(\mathbf x) - E \bigr) \, d\mathbf x
  .
  \notag
  %\label{eq:dOmegaE}
\end{align}
%
where we have integrated by parts in the last step.
%
Thus, we have from Eq. \eqref{eq:betaE_def} that
%
\begin{equation}
  \beta(E)
  =
  \left\langle
    \nabla \cdot \mathbf u
  \right\rangle_E
  .
  \label{eq:betaE_average}
\end{equation}
%
Although the vector field $\mathbf u$ may involve both coordinates and momenta,
a convenient choice of $\mathbf u$ that satisfies
Eq. \eqref{eq:unormalization}
is one derived entirely from the momenta
%
\begin{equation}
  \mathbf u
  =
  \frac{ \mathbf p }
       {  2 \, K }
  ,
  \label{eq:u_def}
\end{equation}
where $\mathbf v$ is the velocity vector in the phase space
with the components for coordinates being zeroes,
and $K = \frac 1 2 \mathbf p \cdot \mathbf M^{-1} \cdot \mathbf p$
is the kinetic energy ($\mathbf M$ is the diagonal mass matrix).
%
Equation \eqref{eq:unormalization} is satisfied
because
$\mathbf u \cdot \nabla H
= (\mathbf p \cdot \nabla_{\mathbf p} K)/(2 \, K)
= \mathbf p \cdot (\mathbf M^{-1} \cdot \mathbf p) / (2 \, K) = 1$.
%
Using Eq. \eqref{eq:u_def} in Eq. \eqref{eq:betaE_average} yields Eq. \eqref{eq:betaE_invK}

In a similar manner, we have
%
\begin{align*}
  \frac
  {
    d \beta(E)
  }
  {
    d E
  }
  =
  \frac
  {
    \Omega''(E)
  }
  {
    \Omega(E)
  }
  -
  \left[
    \frac
    {
      \Omega'(E)
    }
    {
      \Omega(E)
    }
  \right]^2
  ,
\end{align*}
%
and
%
\begin{align*}
  \Omega''(E)
  &= -\int \nabla \cdot \mathbf u \,
     \delta'\bigl( H(\mathbf x) - E \bigr) \, d\mathbf x
  \\
  &= \int
     \nabla \cdot \bigl( (\nabla \cdot \mathbf u) \, \mathbf u \bigr) \,
     \delta\bigl( H(\mathbf x) - E \bigr) \, d\mathbf x
  \\
  &= \int
     \left[
     \mathbf u \cdot \nabla (\nabla \cdot \mathbf u)
     +
     (\nabla \cdot \mathbf u)^2
     \right]
     \delta\bigl( H(\mathbf x) - E \bigr) \, d\mathbf x
  .
\end{align*}
%
This means
%
\begin{align*}
  \beta'(E)
  =
  \left\langle
     \mathbf u \cdot \nabla (\nabla \cdot \mathbf u)
  \right\rangle_E
  +
  \left\langle
    \Delta (\nabla \cdot \mathbf u)^2
  \right\rangle_E
  .
\end{align*}
%
With Eq. \eqref{eq:u_def},
this yields Eq. \eqref{eq:dbetadE}.

Note that in the above derivation
we have, for simplicity, ignored the conservation
of total momenta\cite{shirts2006, uline2008},
which gives additional constraints satisfied in a typical MD simulation.
%
Fortunately, with the particular choice given by Eq. \eqref{eq:u_def},
one can show that this effect is negligible for a system
with zero total momenta\cite{uline2008}.



\subsection{Model system}


Consider the model Hamiltonian of $\mathbf x = (\mathbf r, \mathbf v)$,
\begin{equation}
  H(\mathbf x)
  =
  \frac{\mathbf v^2} { 2 }
  +
  \left( \frac{\mathbf r^2} { 2 } \right)^\theta
  ,
\end{equation}
%
where $K = \frac 1 2 {\mathbf v}^2$ and
$U = \frac 1 2 {\mathbf r}^2$
are the kinetic and potential energy, respectively,
and $\theta$ is a positive free parameter.
Then
\begin{align*}
  \Omega(E)
  &=
  C^2
  \int
    \delta\left( K + U^\theta - E \right) \,
    K^{\frac{ N_f } 2 - 1} \, dK \, U^{\frac{ N_f } 2 - 1} \, dU
  \\
  &=
  \frac{ C^2 } { \theta }
  \int
  K^{\frac{ N_f } 2 - 1} \, (E - K)^{\frac{ N_f }{ 2 \, \theta } - 1}
    \, dK
  \\
  &=
  \frac{ C^2 }{ \theta } \,
  B\left( \frac{ N_f } {2 \, \theta}, \frac{ N_f } 2 \right)
  E^{ \frac{ N_f }{2 \, \theta} + \frac{N_f}{2} - 1 }
  ,
\end{align*}
where
%
$C = 2 \, \pi^{N_f/2} / \Gamma\left( N_f / 2 \right)$,
and
$B(a, b) = \Gamma(a) \, \Gamma(b) / \Gamma(a+b)$
is the beta function.
%
Then, we have
\begin{align*}
\beta(E)
&=
\left(
  \frac{ N_f } { 2 \, \theta } + \frac{ N_f } 2 - 1
\right)
E^{-1}
,
\\
\beta'(E)
&=
-
\left(
  \frac{ N_f } { 2 \, \theta } + \frac{ N_f } 2 - 1
\right)
E^{-2}
\\
\left\langle
  \frac{
    N_f - 2
  }
  {
    2 \, K^2
  }
\right\rangle
&=
  E^{-2}
\left.
  B\left( \frac{ N_f } { 2  \, \theta } - 2, \frac{ N_f } { 2 } \right)
\middle/
  B\left( \frac{ N_f } { 2  \, \theta }, \frac{ N_f } { 2 } \right)
\right.
\\
&=
\frac{ \frac{ N_f } 2 + \frac{ N_f }{2 \, \theta} - 1 }
     { E^2 }
\frac{ \frac{ N_f } 2 + \frac{ N_f }{2 \, \theta} - 2 }
     { \frac{ N_f } 2 - 2 }
.
\end{align*}
This means the ratio defined in Eq. \eqref{eq:gamma_def}
$$
\gamma
=
\frac
{
  \frac{ N_f } 2 - 2
}
{
  \frac{ N_f } 2 + \frac{N_f}{2 \, \theta} - 2
}
,
$$
which lies between $0$ and $1$.

%\bibliographystyle{abbrv}
\bibliography{simul}
\end{document}
